    async def wait_for_task(
        self,
        index_name: str,
        task_id: int,
        timeout: RetryTimeout = RetryTimeout(),
        max_retries: int = 50,
        request_options: Optional[Union[dict, RequestOptions]] = None,
    ) -> GetTaskResponse:
        """
        Helper: Wait for a task to be published (completed) for a given `indexName` and `taskID`.
        """
        self._retry_count = 0

        async def _func(_: GetTaskResponse) -> GetTaskResponse:
            return await self.get_task(index_name, task_id, request_options)

        def _aggregator(_: GetTaskResponse) -> None:
            self._retry_count += 1

        return await create_iterable(
            func=_func,
            aggregator=_aggregator,
            validate=lambda _resp: _resp.status == "published",
            timeout=lambda: timeout(self._retry_count),
            error_validate=lambda x: self._retry_count >= max_retries,
            error_message=lambda: f"The maximum number of retries exceeded. (${self._retry_count}/${max_retries})",
        )

    async def wait_for_api_key(
        self,
        operation: str,
        key: str,
        api_key: Optional[ApiKey] = None,
        max_retries: int = 50,
        timeout: RetryTimeout = RetryTimeout(),
        request_options: Optional[Union[dict, RequestOptions]] = None,
    ) -> GetApiKeyResponse:
        """
        Helper: Wait for an API key to be added, updated or deleted based on a given `operation`.
        """
        self._retry_count = 0

        if operation == "update" and api_key is None:
            raise ValueError(
                "`apiKey` is required when waiting for an `update` operation."
            )

        async def _func(_prev: GetApiKeyResponse) -> GetApiKeyResponse:
            try:
                return await self.get_api_key(key=key, request_options=request_options)
            except RequestException as e:
                if e.status_code == 404 and (operation == "delete" or operation == "add"):
                    return None
                raise e

        def _aggregator(_: GetApiKeyResponse) -> None:
            self._retry_count += 1

        def _validate(_resp: GetApiKeyResponse) -> bool:
            if operation == "update":
                for field in api_key:
                    if isinstance(api_key[field], list) and isinstance(_resp[field], list):
                        if len(api_key[field]) != len(_resp[field]) or any(
                            v != _resp[field][i] for i, v in enumerate(api_key[field])
                        ):
                            return False
                    elif api_key[field] != _resp[field]:
                        return False
                return True
            elif operation == "add":
                return _resp is not None
            return _resp is None

        return await create_iterable(
            func=_func,
            validate=_validate,
            aggregator=_aggregator,
            timeout=lambda: timeout(self._retry_count),
            error_validate=lambda _: self._retry_count >= max_retries,
            error_message=lambda _: f"The maximum number of retries exceeded. (${self._retry_count}/${max_retries})",
        )

    async def browse_objects(
        self,
        index_name: str,
        aggregator: Optional[Callable[[BrowseResponse], None]],
        browse_params: Optional[BrowseParams] = None,
        request_options: Optional[Union[dict, RequestOptions]] = None,
    ) -> BrowseResponse:
        """
        Helper: Iterate on the `browse` method of the client to allow aggregating objects of an index.
        """
        async def _func(_prev: BrowseResponse) -> BrowseResponse:
            if _prev is not None and _prev.cursor is not None:
                browse_params.cursor = _prev.cursor
            return await self.browse(
                index_name=index_name,
                browse_params=browse_params,
                request_options=request_options,
            )

        return await create_iterable(
            func=_func,
            validate=lambda _resp: _resp.cursor is None,
            aggregator=aggregator,
        )

    async def browse_rules(
        self,
        index_name: str,
        aggregator: Optional[Callable[[SearchRulesResponse], None]],
        search_rules_params: Optional[SearchRulesParams] = SearchRulesParams(hits_per_page=1000),
        request_options: Optional[Union[dict, RequestOptions]] = None,
    ) -> SearchRulesResponse:
        """
        Helper: Iterate on the `search_rules` method of the client to allow aggregating rules of an index.
        """
        if search_rules_params is not None:
            search_rules_params.hits_per_page = 1000

        async def _func(_prev: SearchRulesResponse) -> SearchRulesResponse:
            if _prev is not None:
                search_rules_params.page = _prev.page + 1
            return await self.search_rules(
                index_name=index_name,
                search_rules_params=search_rules_params,
                request_options=request_options,
            )
        return await create_iterable(
            func=_func,
            validate=lambda _resp: _resp.nb_hits < search_rules_params.hits_per_page,
            aggregator=aggregator,
        )

    async def browse_synonyms(
        self,
        index_name: str,
        aggregator: Callable[[SearchSynonymsResponse], None],
        search_synonyms_params: Optional[SearchSynonymsParams] = SearchSynonymsParams(),
        request_options: Optional[Union[dict, RequestOptions]] = None,
    ) -> SearchSynonymsResponse:
        """
        Helper: Iterate on the `search_synonyms` method of the client to allow aggregating synonyms of an index.
        """
        if search_synonyms_params.page is None:
            search_synonyms_params.page = 0
        search_synonyms_params.hits_per_page = 1000

        async def _func(_prev: SearchRulesResponse) -> SearchRulesResponse:
            resp = await self.search_synonyms(
                index_name=index_name,
                search_synonyms_params=search_synonyms_params,
                request_options=request_options,
            )
            search_synonyms_params.page += 1
            return resp
        return await create_iterable(
            func=_func,
            validate=lambda _resp: _resp.nb_hits < search_synonyms_params.hits_per_page,
            aggregator=aggregator,
        )