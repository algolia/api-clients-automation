// {{{generationBanner}}}

import { createIterablePromise } from '@algolia/client-common';
import type { ApiError, ClientOptions, RequestOptions } from '@algolia/client-common';

{{#dependencies}}
import { {{{dependencyName}}}Client } from '{{{dependencyPackage}}}';
import type { {{#lambda.titlecase}}{{{dependencyName}}}{{/lambda.titlecase}}Client } from '{{{dependencyPackage}}}';
{{/dependencies}}

import type { ChunkedBatchOptions, ReplaceAllObjectsOptions, ReplaceAllObjectsWithTransformationResponse } from '@algolia/client-search';
import type { PartialUpdateObjectsOptions, SaveObjectsOptions } from '@algolia/client-search';
import type { PushTaskRecords, WatchResponse } from '@algolia/ingestion';

import type {
  InitClientOptions,
  {{#dependencies}}
  {{#dependencyHasRegionalHosts}}
  {{#lambda.titlecase}}{{{dependencyName}}}Region{{/lambda.titlecase}},
  {{#lambda.titlecase}}{{{dependencyName}}}RegionOptions{{/lambda.titlecase}},
  {{/dependencyHasRegionalHosts}}
  {{/dependencies}}
} from './models';

export * from './models';

export type Algoliasearch = SearchClient & {
  {{#dependencies}}
  {{#withInitMethod}}
  init{{#lambda.titlecase}}{{{dependencyName}}}{{/lambda.titlecase}}: (initOptions{{^dependencyHasRegionalHosts}}?{{/dependencyHasRegionalHosts}}: InitClientOptions {{#dependencyHasRegionalHosts}}& {{#lambda.titlecase}}{{{dependencyName}}}RegionOptions{{/lambda.titlecase}}{{/dependencyHasRegionalHosts}}) => {{#lambda.titlecase}}{{{dependencyName}}}{{/lambda.titlecase}}Client;
  {{/withInitMethod}}
  {{/dependencies}}

  // Bridge helpers to expose along with the search endpoints at the root of the API client

  /**
   * Helper: Similar to the `saveObjects` method but requires a Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/) to be created first, in order to transform records before indexing them to Algolia. The `region` must have been passed to the client instantiation method.
   *
   * @summary Save objects to an Algolia index by leveraging the Transformation pipeline setup using the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/).
   * @param saveObjects - The `saveObjects` object.
   * @param saveObjects.indexName - The `indexName` to save `objects` in.
   * @param saveObjects.objects - The array of `objects` to store in the given Algolia `indexName`.
   * @param saveObjects.batchSize - The size of the chunk of `objects`. The number of `batch` calls will be equal to `length(objects) / batchSize`. Defaults to 1000.
   * @param saveObjects.waitForTasks - Whether or not we should wait until every `batch` tasks has been processed, this operation may slow the total execution time of this method but is more reliable.
   * @param requestOptions - The requestOptions to send along with the query, they will be forwarded to the `batch` method and merged with the transporter requestOptions.
   */
  saveObjectsWithTransformation: (options: SaveObjectsOptions, requestOptions?: RequestOptions | undefined) => Promise<WatchResponse>;

  /**
   * Helper: Similar to the `partialUpdateObjects` method but requires a Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/) to be created first, in order to transform records before indexing them to Algolia. The `region` must have been passed to the client instantiation method.
   *
   * @summary Save objects to an Algolia index by leveraging the Transformation pipeline setup in the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/).
   * @param partialUpdateObjects - The `partialUpdateObjects` object.
   * @param partialUpdateObjects.indexName - The `indexName` to update `objects` in.
   * @param partialUpdateObjects.objects - The array of `objects` to update in the given Algolia `indexName`.
   * @param partialUpdateObjects.createIfNotExists - To be provided if non-existing objects are passed, otherwise, the call will fail..
   * @param partialUpdateObjects.batchSize - The size of the chunk of `objects`. The number of `batch` calls will be equal to `length(objects) / batchSize`. Defaults to 1000.
   * @param partialUpdateObjects.waitForTasks - Whether or not we should wait until every `batch` tasks has been processed, this operation may slow the total execution time of this method but is more reliable.
   * @param requestOptions - The requestOptions to send along with the query, they will be forwarded to the `getTask` method and merged with the transporter requestOptions.
   */
  partialUpdateObjectsWithTransformation: (options: PartialUpdateObjectsOptions, requestOptions?: RequestOptions | undefined) => Promise<WatchResponse>;

  /**
   * Helper: Similar to the `replaceAllObjects` method but requires a Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/) to be created first, in order to transform records before indexing them to Algolia. The `region` must have been passed to the client instantiation method.
   *
   * @summary Helper: Replaces all objects (records) in the given `index_name` by leveraging the Transformation pipeline setup in the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/) with the given `objects`. A temporary index is created during this process in order to backup your data.
   * @param replaceAllObjects - The `replaceAllObjects` object.
   * @param replaceAllObjects.indexName - The `indexName` to replace `objects` in.
   * @param replaceAllObjects.objects - The array of `objects` to store in the given Algolia `indexName`.
   * @param replaceAllObjects.batchSize - The size of the chunk of `objects`. The number of `batch` calls will be equal to `objects.length / batchSize`. Defaults to 1000.
   * @param replaceAllObjects.scopes - The `scopes` to keep from the index. Defaults to ['settings', 'rules', 'synonyms'].
   * @param requestOptions - The requestOptions to send along with the query, they will be forwarded to the `batch`, `operationIndex` and `getTask` method and merged with the transporter requestOptions.
   */
  replaceAllObjectsWithTransformation: (
    options: ReplaceAllObjectsOptions,
    requestOptions?: RequestOptions | undefined,
  ) => Promise<ReplaceAllObjectsWithTransformationResponse>;

  /**
   * Helper: Chunks the given `objects` list in subset of 1000 elements max in order to make it fit in `push` requests by leveraging the Transformation pipeline setup in the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/).
   *
   * @summary Helper: Chunks the given `objects` list in subset of 1000 elements max in order to make it fit in `batch` requests.
   * @param chunkedPush - The `chunkedPush` object.
   * @param chunkedPush.indexName - The `indexName` to replace `objects` in.
   * @param chunkedPush.objects - The array of `objects` to store in the given Algolia `indexName`.
   * @param chunkedPush.action - The `batch` `action` to perform on the given array of `objects`, defaults to `addObject`.
   * @param chunkedPush.waitForTasks - Whether or not we should wait until every `batch` tasks has been processed, this operation may slow the total execution time of this method but is more reliable.
   * @param chunkedPush.batchSize - The size of the chunk of `objects`. The number of `batch` calls will be equal to `length(objects) / batchSize`. Defaults to 1000.
   * @param requestOptions - The requestOptions to send along with the query, they will be forwarded to the `getEvent` method and merged with the transporter requestOptions.
   */
  chunkedPush: (options: ChunkedBatchOptions, requestOptions?: RequestOptions) => Promise<Array<WatchResponse>>;
};

export type TransformationOptions = {
  // When provided, a second transporter will be created in order to leverage the `*WithTransformation` methods exposed by the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/).
  transformation?: {
    // The region of your Algolia application ID, used to target the correct hosts of the transformation service.
    region: IngestionRegion;
  } | undefined;
};

export function algoliasearch(
  appId: string,
  apiKey: string,
  options?: ClientOptions & TransformationOptions | undefined,
): Algoliasearch {
  if (!appId || typeof appId !== 'string') {
    throw new Error('`appId` is missing.');
  }

  if (!apiKey || typeof apiKey !== 'string') {
    throw new Error('`apiKey` is missing.');
  }

  const client = searchClient(appId, apiKey, options);

  let ingestionTransporter: IngestionClient | undefined;

  if (options?.transformation) {
    if (!options.transformation.region) {
      throw new Error('`region` must be provided when leveraging the transformation pipeline');
    }

    ingestionTransporter = ingestionClient(appId, apiKey, options.transformation.region, options);
  }

  return {
    ...client,

    async saveObjectsWithTransformation({ indexName, objects, waitForTasks }, requestOptions): Promise<WatchResponse> {
      if (!ingestionTransporter) {
        throw new Error('`transformation.region` must be provided at client instantiation before calling this method.');
      }

      if (!options?.transformation?.region) {
        throw new Error('`region` must be provided when leveraging the transformation pipeline');
      }

      return ingestionTransporter?.push(
        {
          indexName,
          watch: waitForTasks,
          pushTaskPayload: {
            action: 'addObject',
            records: objects as PushTaskRecords[],
          },
        },
        requestOptions,
      );
    },

    async partialUpdateObjectsWithTransformation(
      { indexName, objects, createIfNotExists, waitForTasks },
      requestOptions,
    ): Promise<WatchResponse> {
      if (!ingestionTransporter) {
        throw new Error('`transformation.region` must be provided at client instantiation before calling this method.');
      }

      if (!options?.transformation?.region) {
        throw new Error('`region` must be provided when leveraging the transformation pipeline');
      }

      return ingestionTransporter?.push(
        {
          indexName,
          watch: waitForTasks,
          pushTaskPayload: {
            action: createIfNotExists ? 'partialUpdateObject' : 'partialUpdateObjectNoCreate',
            records: objects as PushTaskRecords[],
          },
        },
        requestOptions,
      );
    },

    async chunkedPush(
      { indexName, objects, action = 'addObject', waitForTasks, batchSize = 1000 }: ChunkedBatchOptions,
      requestOptions?: RequestOptions,
    ): Promise<Array<WatchResponse>> {
      if (!ingestionTransporter) {
        throw new Error('`transformation.region` must be provided at client instantiation before calling this method.');
      }

      if (!options?.transformation?.region) {
        throw new Error('`region` must be provided when leveraging the transformation pipeline');
      }

      let records: Array<PushTaskRecords> = [];
      const responses: Array<WatchResponse> = [];

      const objectEntries = objects.entries();
      for (const [i, obj] of objectEntries) {
        records.push(obj as PushTaskRecords);
        if (records.length === batchSize || i === objects.length - 1) {
          responses.push(
            await ingestionTransporter.push(
              { indexName, pushTaskPayload: { action, records }, watch: waitForTasks },
              requestOptions,
            ),
          );
          records = [];
        }
      }

      let retryCount = 0;

      if (waitForTasks) {
        for (const resp of responses) {
          if (!resp.eventID) {
            throw new Error('received unexpected response from the push endpoint, eventID must not be undefined');
          }

          await createIterablePromise({
            func: async () => {
              if (resp.eventID === undefined || !resp.eventID) {
                throw new Error('received unexpected response from the push endpoint, eventID must not be undefined');
              }

              return ingestionTransporter.getEvent({ runID: resp.runID, eventID: resp.eventID }).catch((error: ApiError) => {
                if (error.status === 404) {
                  return undefined;
                }

                throw error;
              })
            },
            validate: (response) => response !== undefined,
            aggregator: () => (retryCount += 1),
            error: {
              validate: () => retryCount >= 50,
              message: () => `The maximum number of retries exceeded. (${retryCount}/${50})`,
            },
            timeout: (): number => Math.min(retryCount * 500, 5000),
          });
        }
      }

      return responses;
    },

    async replaceAllObjectsWithTransformation(
      { indexName, objects, batchSize, scopes }: ReplaceAllObjectsOptions,
      requestOptions?: RequestOptions | undefined,
    ): Promise<ReplaceAllObjectsWithTransformationResponse> {
      if (!ingestionTransporter) {
        throw new Error('`transformation.region` must be provided at client instantiation before calling this method.');
      }

      if (!options?.transformation?.region) {
        throw new Error('`region` must be provided when leveraging the transformation pipeline');
      }

      const randomSuffix = Math.floor(Math.random() * 1000000) + 100000;
      const tmpIndexName = `${indexName}_tmp_${randomSuffix}`;

      if (scopes === undefined) {
        scopes = ['settings', 'rules', 'synonyms'];
      }

      try {
        let copyOperationResponse = await this.operationIndex(
          {
            indexName,
            operationIndexParams: {
              operation: 'copy',
              destination: tmpIndexName,
              scope: scopes,
            },
          },
          requestOptions,
        );

        const watchResponses = await this.chunkedPush(
          { indexName: tmpIndexName, objects, waitForTasks: true, batchSize },
          requestOptions,
        );

        await this.waitForTask({
          indexName: tmpIndexName,
          taskID: copyOperationResponse.taskID,
        });

        copyOperationResponse = await this.operationIndex(
          {
            indexName,
            operationIndexParams: {
              operation: 'copy',
              destination: tmpIndexName,
              scope: scopes,
            },
          },
          requestOptions,
        );
        await this.waitForTask({
          indexName: tmpIndexName,
          taskID: copyOperationResponse.taskID,
        });

        const moveOperationResponse = await this.operationIndex(
          {
            indexName: tmpIndexName,
            operationIndexParams: { operation: 'move', destination: indexName },
          },
          requestOptions,
        );
        await this.waitForTask({
          indexName: tmpIndexName,
          taskID: moveOperationResponse.taskID,
        });

        return { copyOperationResponse, watchResponses, moveOperationResponse };
      } catch (error) {
        await this.deleteIndex({ indexName: tmpIndexName });

        throw error;
      }
    },

    /**
     * Get the value of the `algoliaAgent`, used by our libraries internally and telemetry system.
     */
    get _ua(): string {
      return client.transporter.algoliaAgent.value;
    },

    {{#dependencies}}
    {{#withInitMethod}}
    init{{#lambda.titlecase}}{{{dependencyName}}}{{/lambda.titlecase}}: (initOptions: InitClientOptions {{#dependencyHasRegionalHosts}}& {{#lambda.titlecase}}{{{dependencyName}}}RegionOptions{{/lambda.titlecase}}{{/dependencyHasRegionalHosts}}{{^dependencyHasRegionalHosts}}={}{{/dependencyHasRegionalHosts}}): {{#lambda.titlecase}}{{{dependencyName}}}{{/lambda.titlecase}}Client => {
      return {{{dependencyName}}}Client(initOptions.appId || appId, initOptions.apiKey || apiKey, {{#dependencyHasRegionalHosts}}initOptions.region,{{/dependencyHasRegionalHosts}}initOptions.options);
    },
    {{/withInitMethod}}

    {{/dependencies}}
  }
}