/**
 * Helper: Chunks the given `objects` list in subset of 1000 elements max in order to make it fit in `push` requests by leveraging the Transformation pipeline setup in the Push connector (https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/connectors/push/).
 *
 * @summary Helper: Chunks the given `objects` list in subset of 1000 elements max in order to make it fit in `batch` requests.
 * @param chunkedPush - The `chunkedPush` object.
 * @param chunkedPush.indexName - The `indexName` to replace `objects` in.
 * @param chunkedPush.objects - The array of `objects` to store in the given Algolia `indexName`.
 * @param chunkedPush.action - The `batch` `action` to perform on the given array of `objects`, defaults to `addObject`.
 * @param chunkedPush.waitForTasks - Whether or not we should wait until every `batch` tasks has been processed, this operation may slow the total execution time of this method but is more reliable.
 * @param chunkedPush.batchSize - The size of the chunk of `objects`. The number of `batch` calls will be equal to `length(objects) / batchSize`. Defaults to 1000.
 * @param chunkedPush.referenceIndexName - This is required when targeting an index that does not have a push connector setup (e.g. a tmp index), but you wish to attach another index's transformation to it (e.g. the source index name).
 * @param requestOptions - The requestOptions to send along with the query, they will be forwarded to the `getEvent` method and merged with the transporter requestOptions.
 */
async chunkedPush(
  {
    indexName,
    objects,
    action = 'addObject',
    waitForTasks,
    batchSize = 1000,
    referenceIndexName,
  }: ChunkedPushOptions,
  requestOptions?: RequestOptions,
): Promise<Array<WatchResponse>> {
  let records: Array<PushTaskRecords> = [];
  let offset = 0;
  const responses: Array<WatchResponse> = [];
  const waitBatchSize = Math.floor(batchSize / 10) || batchSize;

  const objectEntries = objects.entries();
  for (const [i, obj] of objectEntries) {
    records.push(obj as PushTaskRecords);
    if (records.length === batchSize || i === objects.length - 1) {
      responses.push(
        await this.push({ indexName, pushTaskPayload: { action, records }, referenceIndexName }, requestOptions),
      );
      records = [];
    }

    if (waitForTasks && responses.length > 0 && (responses.length % waitBatchSize === 0 || i === objects.length - 1)) {
      for (const resp of responses.slice(offset, offset+waitBatchSize)) {
        if (!resp.eventID) {
          throw new Error('received unexpected response from the push endpoint, eventID must not be undefined');
        }

        let retryCount = 0;

        await createIterablePromise({
          func: async () => {
            if (resp.eventID === undefined || !resp.eventID) {
              throw new Error('received unexpected response from the push endpoint, eventID must not be undefined');
            }

            return this.getEvent({ runID: resp.runID, eventID: resp.eventID }).catch((error: ApiError) => {
              if (error.status === 404) {
                return undefined;
              }

              throw error;
            });
          },
          validate: (response) => response !== undefined,
          aggregator: () => (retryCount += 1),
          error: {
            validate: () => retryCount >= 50,
            message: () => `The maximum number of retries exceeded. (${retryCount}/${50})`,
          },
          timeout: (): number => Math.min(retryCount * 500, 5000),
        });
      }
      offset += waitBatchSize;
    }
  }

  return responses;
},
