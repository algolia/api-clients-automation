CrawlerIdParameter:
  name: id
  in: path
  description: Crawler ID.
  required: true
  schema:
    $ref: '#/CrawlerID'

CrawlerLogIdParameter:
  name: logId
  in: path
  description: Crawler log ID.
  required: true
  schema:
    $ref: '#/CrawlerLogID'

TaskIdParameter:
  name: taskID
  in: path
  description: Task ID.
  required: true
  schema:
    $ref: '#/TaskID'

CrawlerVersionParameter:
  name: version
  in: path
  description: This crawler's version nmber.
  required: true
  schema:
    type: integer

ItemsPerPage:
  name: itemsPerPage
  in: query
  description: Number of items per page to retrieve.
  schema:
    $ref: '#/itemsPerPage'

Page:
  name: page
  in: query
  description: Page to retrieve.
  schema:
    $ref: '#/page'

From:
  name: from
  in: query
  description: Date 'from' filter.
  schema:
    $ref: '#/from'

Until:
  name: until
  in: query
  description: Date 'until' filter.
  schema:
    $ref: '#/until'

Status:
  name: status
  in: query
  description: Status to filter 'DONE', 'SKIPPED' or 'FAILED'.
  schema:
    $ref: '#/urlsCrawledGroupStatus'

Limit:
  name: limit
  in: query
  description: Limit of the query results.
  schema:
    $ref: '#/limit'

Offset:
  name: offset
  in: query
  description: Offset of the query results.
  schema:
    $ref: '#/offset'

Order:
  name: order
  in: query
  description: Order of the query 'ASC' or 'DESC'.
  schema:
    $ref: '#/order'

Name:
  name: name
  in: query
  description: Name of the crawler for filtering the API response.
  schema:
    $ref: '#/CrawlerName'

AppID:
  name: appID
  in: query
  description: Algolia application ID for filtering the API response.
  schema:
    $ref: '#/applicationID'

applicationID:
  type: string
  description: |
    Algolia application ID where the crawler creates and updates indices.

CrawlerID:
  type: string
  description: Universally unique identifier (UUID) of the crawler.
  example: e0f6db8a-24f5-4092-83a4-1b2c6cb6d809

CrawlerLogID:
  type: string
  description: Universally unique identifier (UUID) of the crawler log.
  example: a2ebb507-ef64-4b6b-9d84-ef66baaa7a80

TaskID:
  type: string
  description: Universally unique identifier (UUID) of the task.
  example: 98458796-b7bb-4703-8b1b-785c1080b110

CrawlerName:
  type: string
  maxLength: 64
  description: Name of the crawler.
  example: test-crawler

UrlsCrawledGroup:
  type: object
  description: Processed URLs and their status.
  properties:
    status:
      $ref: '#/urlsCrawledGroupStatus'
    reason:
      type: string
      description: Reason for this status.
    category:
      $ref: '#/urlsCrawledGroupCategory'
    count:
      type: integer
      description: Number of URLs with this status.
    readable:
      type: string
      description: Reason for this status.
  example:
    status: SKIPPED
    reason: forbidden_by_robotstxt
    category: fetch
    count: 3
    readable: Forbidden by robots.txt

urlsCrawledGroupStatus:
  type: string
  description: |
    Crawled URL status.

    For more information, see [Troubleshooting by crawl status](https://www.algolia.com/doc/tools/crawler/troubleshooting/crawl-status).
  enum:
    - DONE
    - SKIPPED
    - FAILED

urlsCrawledGroupCategory:
  type: string
  description: |
    Step where the status information was generated.

    For more information, see [Troubleshooting by crawl status](https://www.algolia.com/doc/tools/crawler/troubleshooting/crawl-status).
  enum:
    - fetch
    - extraction
    - indexing
    - success

itemsPerPage:
  type: integer
  description: Number of items per page of the paginated API response.
  minimum: 1
  maximum: 100
  default: 20

page:
  type: integer
  description: Current page of the paginated API response.
  minimum: 1
  maximum: 100
  default: 1

total:
  type: integer
  description: Total number of retrievable items.
  example: 100

from:
  type: string
  description: Unix string 'from' date.
  example: 1762264044

until:
  type: string
  description: Unix string 'until' date.
  example: 1762264044

limit:
  type: integer
  description: Limit of the query results.
  minimum: 1
  default: 10
  maximum: 1000
  example: 10

offset:
  type: integer
  description: Offset of the query results.
  example: 11

order:
  type: string
  description: |
    Order of the query.
  enum:
    - ASC
    - DESC

Pagination:
  type: object
  description: Pagination information.
  properties:
    itemsPerPage:
      $ref: '#/itemsPerPage'
    page:
      $ref: '#/page'
    total:
      $ref: '#/total'

version:
  type: integer
  description: Version of the configuration. Version 1 is the initial configuration you used when creating the crawler.
  minimum: 1

authorId:
  type: string
  description: Universally unique identifier (UUID) of the user who created this version of the configuration.
  example: 7d79f0dd-2dab-4296-8098-957a1fdc0637
